# ğŸ¤– LexiAI

**LexiAI** is a private, multilingual AI assistant for working with documents locally â€” powered by open-source LLMs. Ask questions, summarize, and extract information from your files securely and offline.

---

## âœ¨ Features

- ğŸ” Fully local & offline document processing  
- ğŸ§  LLM support via [Ollama](https://ollama.com/)  
- ğŸ“„ Ask questions based on uploaded PDFs, Word docs, etc.  
- ğŸŒ Auto-detects language and replies in the same one  
- ğŸ§© Supports multiple roles: Legal, HR, Tech, General  
- ğŸ’» Desktop (PyQt) or Web (Blazor/.NET) frontend options  

---

## ğŸ“ Folder Structure

```
LexiAI/
â”œâ”€â”€ main.py
â”œâ”€â”€ chat_engine/
â”‚   â””â”€â”€ model_wrapper.py
â”œâ”€â”€ ui/
â”‚   â””â”€â”€ main_window.py
â”œâ”€â”€ assets/
â”‚   â””â”€â”€ logo.png
â”œâ”€â”€ .venv/                # Ignored by Git
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸš€ Getting Started

1. **Clone the repo**
   ```bash
   git clone https://github.com/Saree159/LexiAI.git
   cd LexiAI
   ```

2. **Set up virtual environment**
   ```bash
   python -m venv .venv
   source .venv/bin/activate  # Windows: .venv\Scripts\activate
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Run the app**
   ```bash
   python main.py
   ```

---

## ğŸ§  Models Used

- [LLaMA 3](https://ollama.com/library/llama3)  
- Gemma, Mistral, or any GGUF-compatible model  
- Running via Ollama backend or locally loaded  

---

## ğŸ”§ Tech Stack

- Python  
- LangDetect  
- Ollama  
- PyQt / Blazor (.NET 8)  
- GitHub for version control  

---

## ğŸ“œ License

MIT License Â© 2025 Saree Ali

---

## ğŸ’¡ Contributing

Pull requests welcome!  
For major changes, open an issue first to discuss what youâ€™d like to change.

---

## ğŸ§© Future Ideas

- Web-based UI with chat history & themes  
- Local vector DB (e.g. Chroma) for retrieval-augmented generation (RAG)  
- User roles with custom prompt tuning  

---
